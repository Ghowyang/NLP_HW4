import json
from opencc import OpenCC
import jieba
import re
from gensim.models import word2vec
import numpy

r = '[）\（\：\·\，\。\“ \”\?\？\」\「\……\、\《\》\；\)\(]'
file = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL']
cc = OpenCC('s2t')

def open_wiki():
    result =[]
    for n in file[0:4]:
        for m in range(100):
            for line in open('wiki_zh/{}/wiki_{}'.format(n,str(m).zfill(2))):
                data = json.loads(line)
                value = re.sub(r,'',data['text'])
                result.append(value)
    for n in file[5:8]:
        for m in range(100):
            for line in open('wiki_zh/{}/wiki_{}'.format(n,str(m).zfill(2))): 
                data = json.loads(line)
                value = re.sub(r,'',data['text'])
                result.append(value)
    for n in file[9:11]:
        for m in range(100):
            for line in open('wiki_zh/{}/wiki_{}'.format(n,str(m).zfill(2))):
                data = json.loads(line)
                value = re.sub(r,'',data['text'])
                result.append(value)
    for m in range(74):
        for line in open('wiki_zh/{}/wiki_{}'.format('AM',str(m).zfill(2))):
            data = json.loads(line)
            value = re.sub(r,'',data['text'])
            result.append(value)
            
    return result

def chine(result):
    value = []
    for line in result:
        a = cc.convert(line)
        value.append(a)
    return value
    
def get_stopword_list():       
    with open('wiki_zh/cn_stopwords.txt') as f: 
        stopword_list = [word.strip('\n') for word in f.readlines()]
    return stopword_list
